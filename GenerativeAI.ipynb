{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP9SxpuZjX7oExCdBuNvAgL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"SfL9MOzOqlt7","executionInfo":{"status":"ok","timestamp":1697513136030,"user_tz":-480,"elapsed":5638,"user":{"displayName":"Yu","userId":"00012840565073563757"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Define the generator\n","def build_generator(latent_dim):\n","    model = keras.Sequential()\n","    model.add(layers.Dense(256, input_dim=latent_dim))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.BatchNormalization(momentum=0.8))\n","    model.add(layers.Dense(512))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.BatchNormalization(momentum=0.8))\n","    model.add(layers.Dense(1024))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.BatchNormalization(momentum=0.8))\n","    model.add(layers.Dense(784, activation='tanh'))\n","    model.add(layers.Reshape((28, 28, 1)))\n","    return model\n","\n","# Define the discriminator\n","def build_discriminator(image_shape):\n","    model = keras.Sequential()\n","    model.add(layers.Flatten(input_shape=image_shape))\n","    model.add(layers.Dense(1024))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Dense(512))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Dense(256))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","    return model\n","\n","# Create the GAN\n","def build_gan(generator, discriminator):\n","    discriminator.trainable = False\n","    model = keras.Sequential()\n","    model.add(generator)\n","    model.add(discriminator)\n","    return model\n","\n","# Define GAN parameters\n","latent_dim = 100\n","image_shape = (28, 28, 1)\n","\n","# Build and compile the models\n","generator = build_generator(latent_dim)\n","discriminator = build_discriminator(image_shape)\n","discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\n","gan = build_gan(generator, discriminator)\n","gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\n","\n","# Training loop goes here"]},{"cell_type":"code","source":["import numpy as np\n"],"metadata":{"id":"DGREuksGsyOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import your dataset and preprocess it as needed\n","\n","# Training parameters\n","batch_size = 64\n","epochs = 20000\n","\n","# Training loop\n","for epoch in range(epochs):\n","    # ---------------------\n","    #  Train the Discriminator\n","    # ---------------------\n","\n","    # Select a random batch of real images\n","    idx = np.random.randint(0, X_train.shape[0], batch_size)\n","    real_images = X_train[idx]\n","\n","    # Generate a batch of fake images\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    fake_images = generator.predict(noise)\n","\n","    # Labels for the real and fake images\n","    real_labels = np.ones((batch_size, 1))\n","    fake_labels = np.zeros((batch_size, 1))\n","\n","    # Train the discriminator\n","    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n","    d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","    # ---------------------\n","    #  Train the Generator\n","    # ---------------------\n","\n","    # Generate a batch of noise\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","\n","    # Labels for the generator\n","    valid_labels = np.ones((batch_size, 1))\n","\n","    # Train the generator\n","    g_loss = gan.train_on_batch(noise, valid_labels)\n","\n","    # Print the progress\n","    print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n","\n","    # Optionally, you can save generated images at specific intervals\n","\n","# After training, you can save the generator model for future use\n","generator.save(\"gan_generator.h5\")"],"metadata":{"id":"ZF1M60RmsrBh"},"execution_count":null,"outputs":[]}]}